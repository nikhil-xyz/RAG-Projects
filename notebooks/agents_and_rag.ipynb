{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7b833be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c05d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"MISTRAL_API_KEY\"] = os.getenv(\"MISTRAL_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "97bcd1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper, WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ac8dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_api = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=300)\n",
    "wiki_api = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10797908",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_api)\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=wiki_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "448d18ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_mistralai.embeddings import MistralAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5d39f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"qwen-qwq-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27609aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://js.langchain.com/docs/introduction/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1640f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "008199f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikhil\\.conda\\envs\\rag\\lib\\site-packages\\langchain_mistralai\\embeddings.py:181: UserWarning: Could not download mistral tokenizer from Huggingface for calculating batch sizes. Set a Huggingface token via the HF_TOKEN environment variable to download the real tokenizer. Falling back to a dummy tokenizer that uses `len()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = MistralAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "855df4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "framework for developing applications powered by large language models (LLMs).LangChain simplifies every stage of the LLM application lifecycle:Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations.\n"
     ]
    }
   ],
   "source": [
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "query = \"What is LangChain?\"\n",
    "docs = vector.similarity_search(query, k=1)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "84b76fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'MistralAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000258B2F20220>, search_kwargs={})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d3b82971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(retriever=retriever, name=\"LangChain Docs\", description=\"LangChain documentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e7266c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain Docs'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "883ff125",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [arxiv, wikipedia, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d269c677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikhil\\.conda\\envs\\rag\\lib\\site-packages\\langsmith\\client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8c4a73eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "# from langchain_community.agents import create_groq_tools_agent\n",
    "agent = create_openai_tools_agent(llm=llm, tools=tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b32b59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000258947F2B90>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000258947F2B90>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000258B2C36800>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000258B2C71090>, model_name='qwen-qwq-32b', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'LangChain Docs', 'description': 'LangChain documentation', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=300)), WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\nikhil\\\\.conda\\\\envs\\\\rag\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=300)), Tool(name='LangChain Docs', description='LangChain documentation', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000025894AC6DD0>, retriever=VectorStoreRetriever(tags=['FAISS', 'MistralAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000258B2F20220>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000025894E09000>, retriever=VectorStoreRetriever(tags=['FAISS', 'MistralAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000258B2F20220>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent Executor\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "47567a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `LangChain Docs` with `{'query': 'what is langchain'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mframework for developing applications powered by large language models (LLMs).LangChain simplifies every stage of the LLM application lifecycle:Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations.\n",
      "\n",
      "Use LangGraph.js to build stateful agents with first-class streaming and human-in-the-loop support.Productionization: Use LangSmith to inspect, monitor and evaluate your chains, so that you can continuously optimize and deploy with confidence.Deployment: Turn your LangGraph applications into production-ready APIs and Assistants with LangGraph Cloud.Concretely, the framework consists of the following open-source libraries:@langchain/core: Base abstractions and LangChain Expression Language.@langchain/community: Third party integrations.Partner packages (e.g. @langchain/openai, @langchain/anthropic, etc.): Some integrations have been further split into their own lightweight packages that only depend on @langchain/core.langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture.LangGraph.js: Build robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph.LangSmith: A developer platform that lets you\n",
      "\n",
      "GuideAgentsArchitectureCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (rag)RetrievalRetrieversRunnable interfaceStreamingStructured outputstString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraph.jsVersionsv0.3v0.2Migrating from v0.0 memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryRelease PolicySecurityIntroductionOn this pageIntroductionLangChain is a framework for developing applications powered by large language models (LLMs).LangChain simplifies every stage of the LLM application lifecycle:Development: Build your applications using LangChain's\n",
      "\n",
      "cognitive architecture.LangGraph.js: Build robust and stateful multi-actor applications with LLMs by modeling steps as edges and nodes in a graph.LangSmith: A developer platform that lets you debug, test, evaluate, and monitor LLM applications.noteThese docs focus on the JavaScript LangChain library. Head here for docs on the Python LangChain library.Tutorials​If you're looking to build something specific or are more of a hands-on learner, check out our tutorials.\u001b[0m\u001b[32;1m\u001b[1;3mLangChain is a **development framework** designed to simplify building applications powered by large language models (LLMs). It provides tools and abstractions to streamline the entire lifecycle of LLM-driven applications, from prototyping to deployment. Here's a concise breakdown:\n",
      "\n",
      "### Core Purpose\n",
      "- **Simplifies LLM Application Development**: Offers components for building, testing, and deploying AI apps that leverage LLMs like GPT, Claude, etc.\n",
      "- **Focus Areas**:\n",
      "  1. **Development**: Provides modular building blocks (e.g., chains, agents, retrievers) for constructing AI workflows.\n",
      "  2. **Productionization**: Enables monitoring, evaluation, and optimization via tools like **LangSmith** (for tracing and analysis).\n",
      "  3. **Deployment**: Supports scaling apps into production with state management and APIs (e.g., via **LangGraph.js** for interactive workflows).\n",
      "\n",
      "### Key Components\n",
      "- **@langchain/core**: Foundation with core abstractions and the LangChain Expression Language (LCEL).\n",
      "- **LangGraph.js**: A JavaScript library for creating stateful, multi-step applications modeled as graph workflows (nodes = steps, edges = data flow).\n",
      "- **LangSmith**: A platform for debugging, testing, and monitoring LLM applications, integrating with LangChain code.\n",
      "- **Third-Party Integrations**: Supports models from OpenAI, Anthropic, and others, along with vector databases and tools.\n",
      "\n",
      "### Use Cases\n",
      "- Building chatbots, search engines, or automation tools that require LLM-driven logic.\n",
      "- Creating \"agents\" that can interact with tools, APIs, or documents (via retrieval-augmented generation, RAG).\n",
      "- Streamlining end-to-end workflows (e.g., query → data retrieval → LLM processing → output).\n",
      "\n",
      "### Ecosystem\n",
      "- **Open-source**: Primarily maintained in Python and JavaScript/TypeScript.\n",
      "- **Community-Driven**: Extensive plugins and integrations for common use cases.\n",
      "\n",
      "In short, LangChain acts as a \"swiss army knife\" for developers working with LLMs, abstracting complexity and enabling faster iteration.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is langchain?',\n",
       " 'output': 'LangChain is a **development framework** designed to simplify building applications powered by large language models (LLMs). It provides tools and abstractions to streamline the entire lifecycle of LLM-driven applications, from prototyping to deployment. Here\\'s a concise breakdown:\\n\\n### Core Purpose\\n- **Simplifies LLM Application Development**: Offers components for building, testing, and deploying AI apps that leverage LLMs like GPT, Claude, etc.\\n- **Focus Areas**:\\n  1. **Development**: Provides modular building blocks (e.g., chains, agents, retrievers) for constructing AI workflows.\\n  2. **Productionization**: Enables monitoring, evaluation, and optimization via tools like **LangSmith** (for tracing and analysis).\\n  3. **Deployment**: Supports scaling apps into production with state management and APIs (e.g., via **LangGraph.js** for interactive workflows).\\n\\n### Key Components\\n- **@langchain/core**: Foundation with core abstractions and the LangChain Expression Language (LCEL).\\n- **LangGraph.js**: A JavaScript library for creating stateful, multi-step applications modeled as graph workflows (nodes = steps, edges = data flow).\\n- **LangSmith**: A platform for debugging, testing, and monitoring LLM applications, integrating with LangChain code.\\n- **Third-Party Integrations**: Supports models from OpenAI, Anthropic, and others, along with vector databases and tools.\\n\\n### Use Cases\\n- Building chatbots, search engines, or automation tools that require LLM-driven logic.\\n- Creating \"agents\" that can interact with tools, APIs, or documents (via retrieval-augmented generation, RAG).\\n- Streamlining end-to-end workflows (e.g., query → data retrieval → LLM processing → output).\\n\\n### Ecosystem\\n- **Open-source**: Primarily maintained in Python and JavaScript/TypeScript.\\n- **Community-Driven**: Extensive plugins and integrations for common use cases.\\n\\nIn short, LangChain acts as a \"swiss army knife\" for developers working with LLMs, abstracting complexity and enabling faster iteration.'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\" : \"what is langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6767a0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
